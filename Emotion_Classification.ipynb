{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIt7X6fKvZjb",
        "outputId": "e222a7f9-ad79-4da8-d491-9c7ad7a791fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Number of instances in dataset: 416809\n",
            "| Classifier                | Training Accuracy | Test Accuracy |\n",
            "| ------------------------- | ----------------- | ------------- |\n",
            "| LinearSVC                 |         0.9573216 |     0.8780739 |\n"
          ]
        }
      ],
      "source": [
        "import re \n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "## helper function\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))\n",
        "\n",
        "def read_data(file):\n",
        "    data = []\n",
        "    with open(file, 'r')as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n",
        "            text = line[line.find(\"]\")+1:].strip()\n",
        "            data.append([label, text])\n",
        "    return data\n",
        "\n",
        "file = 'dataset.txt'\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "data = load_from_pickle(directory=\"gdrive/My Drive/merged_training.pkl\")\n",
        "\n",
        "emotions = [ \"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
        "data = data[data[\"emotions\"].isin(emotions)]\n",
        "\n",
        "print(\"Number of instances in dataset: {}\".format(len(data)))\n",
        "\n",
        "\n",
        "def ngram(token, n): \n",
        "    output = []\n",
        "    for i in range(n-1, len(token)): \n",
        "        ngram = ' '.join(token[i-n+1:i+1])\n",
        "        output.append(ngram) \n",
        "    return output\n",
        "\n",
        "def create_feature(text, nrange=(1, 1)):\n",
        "    text_features = [] \n",
        "    text = text.lower() \n",
        "    text_alphanum = re.sub('[^a-z0-9#]', ' ', text)\n",
        "    for n in range(nrange[0], nrange[1]+1): \n",
        "        text_features += ngram(text_alphanum.split(), n)    \n",
        "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
        "    text_features += ngram(text_punc.split(), 1)\n",
        "    return Counter(text_features)\n",
        "\n",
        "def convert_label(item, name): \n",
        "    label = \"\"\n",
        "    for idx in range(len(item)): \n",
        "        if item[idx] == 1: \n",
        "            label += name[idx] + \" \"\n",
        "    \n",
        "    return label.strip()\n",
        "\n",
        "\n",
        "X_all = []\n",
        "y_all = []\n",
        "i = 0\n",
        "while i < len(data):\n",
        "  label = str(data[\"emotions\"].values[i])\n",
        "  text = str(data[\"text\"].values[i])\n",
        "  y_all.append(label.strip())\n",
        "  X_all.append(create_feature(text, nrange=(1, 4)))\n",
        "  i = i + 1\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.2, random_state = 123)\n",
        "\n",
        "def train_test(clf, X_train, X_test, y_train, y_test):\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
        "    test_acc = accuracy_score(y_test, clf.predict(X_test))\n",
        "    return train_acc, test_acc\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "vectorizer = DictVectorizer(sparse = True)\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "\n",
        "# LinearSVC was tested to have the highest accuracy\n",
        "lsvc = LinearSVC(random_state=123)\n",
        "#svc = SVC()\n",
        "#rforest = RandomForestClassifier(random_state=123)\n",
        "#dtree = DecisionTreeClassifier()\n",
        "clifs = [lsvc] \n",
        " \n",
        "print(\"| {:25} | {} | {} |\".format(\"Classifier\", \"Training Accuracy\", \"Test Accuracy\"))\n",
        "print(\"| {} | {} | {} |\".format(\"-\"*25, \"-\"*17, \"-\"*13))\n",
        "for clf in clifs: \n",
        "    clf_name = clf.__class__.__name__\n",
        "    train_acc, test_acc = train_test(clf, X_train, X_test, y_train, y_test)\n",
        "    print(\"| {:25} | {:17.7f} | {:13.7f} |\".format(clf_name, train_acc, test_acc))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_dict = {\"sadness\":\"😢\", \"joy\":\"😂\", \"love\":\"😍\", \"anger\":\"😠\", \"fear\":\"😱\", \"surprise\":\"😳\"}\n",
        "\n",
        "check = input(\"Enter a sentence or enter BYE to stop... \\n\")\n",
        "\n",
        "while check != \"BYE\":\n",
        "  text = str(check)\n",
        "  features = create_feature(text, nrange=(1, 4))\n",
        "  features = vectorizer.transform(features)\n",
        "  prediction = clf.predict(features)[0]\n",
        "  print(\"(Emotion: \"+ prediction + \" \" + emoji_dict[prediction] + \")\")\n",
        "  check = input(\"Enter a sentence or enter END to stop... \\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ8FGBkp97U_",
        "outputId": "994a741c-5c9f-42fc-d31e-41e7d848a747"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a sentence or enter BYE to stop... \n",
            "My dog died yesterday\n",
            "(Emotion: sadness 😢)\n",
            "Enter a sentence or enter END to stop... \n",
            "I feel romantic especially around valentines day\n",
            "(Emotion: love 😍)\n",
            "Enter a sentence or enter END to stop... \n",
            "Today was such a fun day\n",
            "(Emotion: joy 😂)\n",
            "Enter a sentence or enter END to stop... \n",
            "i don't like to feel uncomfortable with being alone\n",
            "(Emotion: fear 😱)\n",
            "Enter a sentence or enter END to stop... \n",
            "oh no you didnt\n",
            "(Emotion: anger 😠)\n",
            "Enter a sentence or enter END to stop... \n",
            "My friend broke my phone\n",
            "(Emotion: sadness 😢)\n",
            "Enter a sentence or enter END to stop... \n",
            "BYE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_4-Sj0utAYjj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}